{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Building Heterogenous Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Student 1 Name: Finola Cahill\n",
    "- Student 1 Number: 07645074"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted, check_random_state\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import load_iris\n",
    "import itertools\n",
    "from itertools import chain, combinations\n",
    "import random\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: The Heterogenous Ensemble Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define HeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class HeterogenousEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer. Base models are different due to different hyper-parameters used.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator: scikit-learn estimator \n",
    "        The model type to be used at the base layer of the ensemble model.\n",
    "\n",
    "    hp_range_map: dictionary\n",
    "        A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        \n",
    "    n_estimators: int\n",
    "        How many models to use in the ensemble\n",
    "        \n",
    "    bootstrap: boolean\n",
    "        Wheter or not to use bootstrap sampling when training base estimators\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels.\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used, unless hyperparameter ranges are specified\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = HeterogenousEnsembleClassifier(tree.DecisionTreeClassifier(), {'max_depth':[5, 10, 15], })\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator = svm.SVC(), n_estimators = 10, hp_range_map = None, bootstrap = True, random_state=None, verbosity = 0):\n",
    "\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: The model type to be used at the base layer of the ensemble model.\n",
    "        hp_range_map: A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        n_estimators: How many models to use in the ensemble\n",
    "        bootstrap: Wheter or not to use bootstrap sampling when training base estimators\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The estimator\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise ranomd state if set\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialise class variabels\n",
    "        self.base_estimator = base_estimator\n",
    "        self.hp_range_map = hp_range_map\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap = bootstrap\n",
    "        self.verbosity = verbosity\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        random.seed(self.random_state)\n",
    "        self.params, self.keys, self.models = [], [], []\n",
    "        \n",
    "        def generate_param_combinations():\n",
    "            params = []\n",
    "            for key, value in self.hp_range_map.items():\n",
    "                params.append(value + [None])\n",
    "                self.keys.append(key)\n",
    "            product = itertools.product(*params)\n",
    "            self.params = [ [ p for p in params ] for params in product ] \n",
    "        \n",
    "        def extract_params(n):\n",
    "            params = {}\n",
    "            for i,key in enumerate(self.keys):\n",
    "                if self.params[n][i] is not None:\n",
    "                    params[key] = self.params[n][i]\n",
    "            return params\n",
    "    \n",
    "        def fit_models(X, y):\n",
    "            for i in range(0, self.n_estimators):\n",
    "                params = extract_params(random.randint(0, (len(self.params)-1)))\n",
    "                clf = copy(self.base_estimator).set_params(**params)\n",
    "                self.models.append(clf.fit(X, y))\n",
    "        #        print(params)\n",
    "        \n",
    "        generate_param_combinations()\n",
    "        fit_models(X,y)\n",
    "    \n",
    "\n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        print(self.models)\n",
    "#         # WRITE CODE HERE\n",
    "    \n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "#     def predict_proba(self, X):\n",
    "        \n",
    "#         # WRITE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL THE ERROR CHECKING ON ALL THE INPUT VARIABLES\n",
    "\n",
    "ARE WE FREE TO CHOOSE HOW TO CYCLE THROUGH THE PARAMETERS???\n",
    "\n",
    "SHOULD THE DEFAULT HP MAP BE NADA??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the HeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 5}\n",
      "{'criterion': 'gini', 'max_depth': 15}\n",
      "{'criterion': 'entropy'}\n",
      "{'max_depth': 15}\n",
      "{'criterion': 'gini'}\n",
      "{'criterion': 'entropy', 'max_depth': 5}\n",
      "{'criterion': 'gini', 'max_depth': 10}\n",
      "{'criterion': 'entropy'}\n",
      "{'criterion': 'gini', 'max_depth': 15}\n",
      "{'max_depth': 10}\n",
      "[DecisionTreeClassifier(criterion='entropy', max_depth=5), DecisionTreeClassifier(max_depth=15), DecisionTreeClassifier(criterion='entropy'), DecisionTreeClassifier(max_depth=15), DecisionTreeClassifier(), DecisionTreeClassifier(criterion='entropy', max_depth=5), DecisionTreeClassifier(max_depth=10), DecisionTreeClassifier(criterion='entropy'), DecisionTreeClassifier(max_depth=15), DecisionTreeClassifier(max_depth=10)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "iris = load_iris()\n",
    "clf = HeterogenousEnsembleClassifier(tree.DecisionTreeClassifier(), hp_range_map={'criterion':['gini', 'entropy'], 'max_depth':[5, 10, 15], })\n",
    "clf.fit(iris.data, iris.target)\n",
    "clf.predict(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the HeterogenousEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "base_estimator = svm.SVC()\n",
    "hyperparam_range = {\"kernel\":[\"rbf\", \"linear\"], \"C\":np.arange(0.1, 1.0, 10), \"gamma\":[0.1, 0.5], \"probability\":[True]}\n",
    "n_estimators = 10\n",
    "clf = HeterogenousEnsembleClassifier(base_estimator, n_estimators, hyperparam_range, verbosity = 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "y_pred = clf.predict_proba(iris.data)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: The StackedHeterogenousEnsembleClassifier Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define StackedHeterogenousEnsembleClassifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class StackedHeterogenousEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer. Base models are different due to different hyper-parameters used. Aggrefgattion is perfomred using a stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator: scikit-learn estimator \n",
    "        The model type to be used at the base layer of the ensemble model.\n",
    "\n",
    "    hp_range_map: dictionary\n",
    "        A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        \n",
    "    n_estimators: int\n",
    "        How many models to use in the ensemble\n",
    "        \n",
    "    bootstrap: boolean\n",
    "        Whether or not to use bootstrap sampling wehn training base estimators\n",
    "    \n",
    "    stack_layer_estimator: scikit-learn estimator \n",
    "        Estimator type of the stack  layer model\n",
    "        \n",
    "    base_stack_data_ratio: float\n",
    "        The ratio with which to split the data for straing the base and stack layers.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used, unless hyperparameter ranges are specified\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedHeterogenousEnsembleClassifier(tree.DecisionTreeClassifier(), {'max_depth':[5, 10, 15], })\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator = svm.SVC(), n_estimators = 10, hp_range_map = None, bootstrap = True, stack_layer_estimator = svm.SVC(), base_stack_data_ratio = 0.7, random_state=None, verbosity = 0):\n",
    "\n",
    "        \"\"\"Setup a StackedHeterogenousEnsembleClassifier classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: The model type to be used at the base layer of the ensemble model.\n",
    "        hp_range_map: A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        n_estimators: How many models to use in the ensemble\n",
    "        bootstrap: Wheter or not to use bootstrap sampling wehn training base estimators\n",
    "        stack_layer_estimator: Estimator type of the stack  layer model\n",
    "        base_stack_data_ratio: The ratio with which to split the data for straing the base and stack layers.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The estimator\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise ranomd state if set\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialise class variabels\n",
    "        self.base_estimator = base_estimator\n",
    "        self.hp_range_map = hp_range_map\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap = bootstrap\n",
    "        self.stack_layer_estimator = stack_layer_estimator\n",
    "        self.base_stack_data_ratio = base_stack_data_ratio\n",
    "        self.verbosity = verbosity\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "                \n",
    "        # WRITE CODE HERE\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # WRITE CODE HERE\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        # WRITE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the StackedHeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the StackedHeterogenousEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "n_estimators = 10\n",
    "base_estimator = svm.SVC()\n",
    "hyperparam_range = {\"kernel\":[\"rbf\", \"linear\"], \"C\":np.arange(0.1, 1.0, 0.1), \"gamma\":[0.1, 0.5], \"probability\":[True]}\n",
    "clf = StackedHeterogenousEnsembleClassifier(base_estimator, n_estimators, hyperparam_range, True, svm.SVC(probability=True), 0.7, verbosity = 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "y_pred = clf.predict_proba(iris.data)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare the Performance of the Different Ensembles Defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Experiment Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Sensorless_drive_diagnosis.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Evaluation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your refelcection here (max 300 words)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

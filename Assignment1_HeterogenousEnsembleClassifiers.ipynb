{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Building Heterogenous Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Student 1 Name: Finola Cahill\n",
    "- Student 1 Number: 07645074"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted, check_random_state\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import load_iris\n",
    "import itertools\n",
    "from itertools import chain, combinations\n",
    "import random\n",
    "from copy import copy\n",
    "from scipy import stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: The Heterogenous Ensemble Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define HeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class HeterogenousEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer. Base models are different due to different hyper-parameters used.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator: scikit-learn estimator \n",
    "        The model type to be used at the base layer of the ensemble model.\n",
    "\n",
    "    hp_range_map: dictionary\n",
    "        A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        \n",
    "    n_estimators: int\n",
    "        How many models to use in the ensemble\n",
    "        \n",
    "    bootstrap: boolean\n",
    "        Wheter or not to use bootstrap sampling when training base estimators\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels.\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used, unless hyperparameter ranges are specified\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = HeterogenousEnsembleClassifier(tree.DecisionTreeClassifier(), {'max_depth':[5, 10, 15], })\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator = svm.SVC(), n_estimators = 10, hp_range_map = None, bootstrap = True, random_state=None, verbosity = 0):\n",
    "\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: The model type to be used at the base layer of the ensemble model.\n",
    "        hp_range_map: A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        n_estimators: How many models to use in the ensemble\n",
    "        bootstrap: Wheter or not to use bootstrap sampling when training base estimators\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The estimator\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise ranomd state if set\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialise class variabels\n",
    "        self.base_estimator = base_estimator\n",
    "        self.hp_range_map = hp_range_map\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap = bootstrap\n",
    "        self.verbosity = verbosity\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "        random.seed(self.random_state)\n",
    "        self.params, self.keys, self.models = [], [], []\n",
    "        \n",
    "         # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        def generate_param_combinations():\n",
    "            params = []\n",
    "            for key, value in self.hp_range_map.items():\n",
    "                if type(value) != list:\n",
    "                    value = [value]\n",
    "                params.append(value + [None])\n",
    "                self.keys.append(key)\n",
    "            product = itertools.product(*params)\n",
    "            self.params = [ [ p for p in params ] for params in product ] \n",
    "        \n",
    "        def extract_params(n):\n",
    "            params = {}\n",
    "            for i,key in enumerate(self.keys):\n",
    "                if self.params[n][i] is not None:\n",
    "                    params[key] = self.params[n][i]\n",
    "            return params\n",
    "    \n",
    "        def fit_models(X, y):\n",
    "            for i in range(0, self.n_estimators):\n",
    "                params = extract_params(random.randint(0, (len(self.params)-1)))\n",
    "                clf = copy(self.base_estimator).set_params(**params)\n",
    "                self.models.append(clf.fit(X, y))\n",
    "        #        print(params)\n",
    "        \n",
    "        generate_param_combinations()\n",
    "        fit_models(X,y)\n",
    "    \n",
    "\n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "\n",
    "        ensemble_predictions = list()\n",
    "        \n",
    "        for model in self.models:\n",
    "            ensemble_predictions.append(model.predict(X))\n",
    "        \n",
    "        ensemble_predictions = np.array(ensemble_predictions)\n",
    "        \n",
    "        results = stats.mode(ensemble_predictions)[0]\n",
    "        \n",
    "        return results[0]\n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "#     def predict_proba(self, X):\n",
    "        \n",
    "#         # WRITE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL THE ERROR CHECKING ON ALL THE INPUT VARIABLES\n",
    "\n",
    "ARE WE FREE TO CHOOSE HOW TO CYCLE THROUGH THE PARAMETERS???\n",
    "\n",
    "SHOULD THE DEFAULT HP MAP BE NADA??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the HeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# iris = load_iris()\n",
    "# clf = HeterogenousEnsembleClassifier(tree.DecisionTreeClassifier(), hp_range_map={'criterion':['gini', 'entropy'], 'max_depth':[1, 5, 10, 15, 20, 25], })\n",
    "# clf.fit(iris.data, iris.target)\n",
    "# clf.predict(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the HeterogenousEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.94      0.96      0.95        50\n",
      "           2       0.96      0.94      0.95        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  48   2   50\n",
       "2           0   3  47   50\n",
       "All        50  51  49  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'HeterogenousEnsembleClassifier' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-38a49ca104f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Confusion Matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'True'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HeterogenousEnsembleClassifier' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "base_estimator = svm.SVC()\n",
    "hyperparam_range = {\"kernel\":[\"rbf\", \"linear\"], \"C\":np.arange(0.1, 1.0, 10), \"gamma\":[0.1, 0.5], \"probability\":[True]}\n",
    "n_estimators = 10\n",
    "clf = HeterogenousEnsembleClassifier(base_estimator, n_estimators, hyperparam_range, verbosity = 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "y_pred = clf.predict_proba(iris.data)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         1.         0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "0.9800000000000001  +/-  0.030550504633038926\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: The StackedHeterogenousEnsembleClassifier Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define StackedHeterogenousEnsembleClassifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class StackedHeterogenousEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer. Base models are different due to different hyper-parameters used. Aggrefgattion is perfomred using a stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator: scikit-learn estimator \n",
    "        The model type to be used at the base layer of the ensemble model.\n",
    "\n",
    "    hp_range_map: dictionary\n",
    "        A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        \n",
    "    n_estimators: int\n",
    "        How many models to use in the ensemble\n",
    "        \n",
    "    bootstrap: boolean\n",
    "        Whether or not to use bootstrap sampling wehn training base estimators\n",
    "    \n",
    "    stack_layer_estimator: scikit-learn estimator \n",
    "        Estimator type of the stack  layer model\n",
    "        \n",
    "    base_stack_data_ratio: float\n",
    "        The ratio with which to split the data for straing the base and stack layers.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used, unless hyperparameter ranges are specified\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedHeterogenousEnsembleClassifier(tree.DecisionTreeClassifier(), {'max_depth':[5, 10, 15], })\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator = svm.SVC(), n_estimators = 10, hp_range_map = None, bootstrap = True, stack_layer_estimator = svm.SVC(), base_stack_data_ratio = 0.7, random_state=None, verbosity = 0):\n",
    "\n",
    "        \"\"\"Setup a StackedHeterogenousEnsembleClassifier classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: The model type to be used at the base layer of the ensemble model.\n",
    "        hp_range_map: A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        n_estimators: How many models to use in the ensemble\n",
    "        bootstrap: Wheter or not to use bootstrap sampling wehn training base estimators\n",
    "        stack_layer_estimator: Estimator type of the stack  layer model\n",
    "        base_stack_data_ratio: The ratio with which to split the data for straing the base and stack layers.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The estimator\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise ranomd state if set\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialise class variabels\n",
    "        self.base_estimator = base_estimator\n",
    "        self.hp_range_map = hp_range_map\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap = bootstrap\n",
    "        self.stack_layer_estimator = stack_layer_estimator\n",
    "        self.base_stack_data_ratio = base_stack_data_ratio\n",
    "        self.verbosity = verbosity\n",
    "        \n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "                \n",
    "        # WRITE CODE HERE\n",
    "\n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # WRITE CODE HERE\n",
    "    \n",
    "    # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        # WRITE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the StackedHeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the StackedHeterogenousEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "n_estimators = 10\n",
    "base_estimator = svm.SVC()\n",
    "hyperparam_range = {\"kernel\":[\"rbf\", \"linear\"], \"C\":np.arange(0.1, 1.0, 0.1), \"gamma\":[0.1, 0.5], \"probability\":[True]}\n",
    "clf = StackedHeterogenousEnsembleClassifier(base_estimator, n_estimators, hyperparam_range, True, svm.SVC(probability=True), 0.7, verbosity = 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "y_pred = clf.predict_proba(iris.data)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare the Performance of the Different Ensembles Defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Experiment Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Sensorless_drive_diagnosis.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Evaluation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your refelcection here (max 300 words)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

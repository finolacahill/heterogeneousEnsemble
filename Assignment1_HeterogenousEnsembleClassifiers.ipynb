{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Building Heterogenous Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Student 1 Name: Finola Cahill\n",
    "- Student 1 Number: 07645074"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted, check_random_state\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import load_iris\n",
    "import itertools\n",
    "from itertools import chain, combinations\n",
    "import random\n",
    "from copy import copy\n",
    "from scipy import stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: The Heterogenous Ensemble Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define HeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class HeterogenousEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer. Base models are different due to different hyper-parameters used.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator: scikit-learn estimator \n",
    "        The model type to be used at the base layer of the ensemble model.\n",
    "\n",
    "    hp_range_map: dictionary\n",
    "        A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        \n",
    "    n_estimators: int\n",
    "        How many models to use in the ensemble\n",
    "        \n",
    "    bootstrap: boolean\n",
    "        Wheter or not to use bootstrap sampling when training base estimators\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels.\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used, unless hyperparameter ranges are specified\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = HeterogenousEnsembleClassifier(tree.DecisionTreeClassifier(), {'max_depth':[5, 10, 15], })\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator = svm.SVC(), n_estimators = 10, hp_range_map = None, bootstrap = True, random_state=None, verbosity = 0):\n",
    "\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: The model type to be used at the base layer of the ensemble model.\n",
    "        hp_range_map: A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        n_estimators: How many models to use in the ensemble\n",
    "        bootstrap: Wheter or not to use bootstrap sampling when training base estimators\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The estimator\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise ranomd state if set\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialise class variabels\n",
    "        self.base_estimator = base_estimator\n",
    "        self.hp_range_map = hp_range_map\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap = bootstrap\n",
    "        self.verbosity = verbosity\n",
    "        self.validate_parameters()\n",
    "    \n",
    "    def validate_parameters(self):\n",
    "        if self.n_estimators < 1:\n",
    "             raise ValueError(\"n_estimators must be >= 1\")\n",
    "        if is_classifier(self.base_estimator) is False:\n",
    "            raise ValueError(\"base_estimator must be a classifier\")\n",
    "        if self.verbosity not in range(0,3):\n",
    "            raise ValueError(\"verbosity has three levels, from 0-2\")\n",
    "        if self.hp_range_map is None:\n",
    "            self.hp_range_map = {}          \n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "                \n",
    "        def checkBootstrap(X, y):\n",
    "            if self.bootstrap is True:\n",
    "                return resample(X,y, replace=True)\n",
    "            return X,y \n",
    "                \n",
    "        def checkValue(value):\n",
    "            if type(value) is np.ndarray:\n",
    "                value = value.tolist()\n",
    "            elif type(value) is not list:\n",
    "                value = [value]\n",
    "            return value + [None]\n",
    "        \n",
    "        def generate_param_combinations():\n",
    "            params = []\n",
    "            for key, value in self.hp_range_map.items():\n",
    "                params.append(checkValue(value))\n",
    "                self.keys.append(key)\n",
    "            product = itertools.product(*params)\n",
    "            self.params = [ [ p for p in params ] for params in product ] \n",
    "        \n",
    "        def extract_params(n):\n",
    "            params = {}\n",
    "            for i,key in enumerate(self.keys):\n",
    "                if self.params[n][i] is not None:\n",
    "                    params[key] = self.params[n][i]\n",
    "            return params\n",
    "    \n",
    "        def fit_models(X, y):\n",
    "            for i in range(0, self.n_estimators):\n",
    "                X_train, y_train = checkBootstrap(X, y)\n",
    "                params = extract_params(random.randint(0, (len(self.params)-1)))\n",
    "                clf = copy(self.base_estimator).set_params(**params)\n",
    "                self.models.append(clf.fit(X_train, y_train))\n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        random.seed(self.random_state)\n",
    "        \n",
    "        self.params, self.keys, self.models = [], [], []\n",
    "        \n",
    "       #  Count the number of occurrences of each class in the target vector (uses mupy unique function that returns a list of unique values and their counts)\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        generate_param_combinations()\n",
    "        \n",
    "        fit_models(X,y)\n",
    "    \n",
    "\n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "    \n",
    "        ensemble_predictions = np.array([model.predict(X) for model in self.models])\n",
    "                \n",
    "        results = stats.mode(ensemble_predictions)[0]\n",
    "        \n",
    "        return results[0]\n",
    "    \n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        X = check_array(X)\n",
    "        \n",
    "        probability = []\n",
    "    \n",
    "        predictions = np.array([model.predict(X) for model in self.models]).transpose()\n",
    "        \n",
    "        for p in predictions:\n",
    "            key, val = np.unique(p, return_counts=True)\n",
    "            counts = dict(zip(key, val))\n",
    "            probability.append([(counts[c] / len(p)) if c in counts else 0.0 for c in self.classes_])\n",
    "        \n",
    "        return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the HeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 0.5, 0.5],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 0.4, 0.6],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 0.2, 0.8],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.7, 0.3],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.3, 0.7],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.2, 0.8],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.4, 0.6],\n",
       " [0.0, 0.2, 0.8],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.4, 0.6],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.5, 0.5],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "iris = load_iris()\n",
    "clf = HeterogenousEnsembleClassifier()\n",
    "clf.fit(iris.data, iris.target)\n",
    "# clf.predict(iris.data)\n",
    "clf.predict_proba(iris.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the HeterogenousEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.96      0.96      0.96        50\n",
      "           2       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  48   2   50\n",
       "2           0   2  48   50\n",
       "All        50  50  50  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "base_estimator = svm.SVC()\n",
    "hyperparam_range = {\"kernel\":[\"rbf\", \"linear\"], \"C\":np.arange(0.1, 1.0, 10), \"gamma\":[0.1, 0.5], \"probability\":[True]}\n",
    "n_estimators = 10\n",
    "clf = HeterogenousEnsembleClassifier(base_estimator, n_estimators, hyperparam_range, verbosity = 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "y_pred = clf.predict_proba(iris.data)\n",
    "y_pred2 = clf.predict(iris.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         1.         0.86666667\n",
      " 0.93333333 0.93333333 1.         1.        ]\n",
      "0.9666666666666668  +/-  0.04472135954999579\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: The StackedHeterogenousEnsembleClassifier Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define StackedHeterogenousEnsembleClassifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class StackedHeterogenousEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer. Base models are different due to different hyper-parameters used. Aggrefgattion is perfomred using a stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator: scikit-learn estimator \n",
    "        The model type to be used at the base layer of the ensemble model.\n",
    "\n",
    "    hp_range_map: dictionary\n",
    "        A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        \n",
    "    n_estimators: int\n",
    "        How many models to use in the ensemble\n",
    "        \n",
    "    bootstrap: boolean\n",
    "        Whether or not to use bootstrap sampling wehn training base estimators\n",
    "    \n",
    "    stack_layer_estimator: scikit-learn estimator \n",
    "        Estimator type of the stack  layer model\n",
    "        \n",
    "    base_stack_data_ratio: float\n",
    "        The ratio with which to split the data for straing the base and stack layers.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used, unless hyperparameter ranges are specified\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedHeterogenousEnsembleClassifier(tree.DecisionTreeClassifier(), {'max_depth':[5, 10, 15], })\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator = svm.SVC(), n_estimators = 10, hp_range_map = None, bootstrap = True, stack_layer_estimator = svm.SVC(), base_stack_data_ratio = 0.7, random_state=None, verbosity = 0):\n",
    "\n",
    "        \"\"\"Setup a StackedHeterogenousEnsembleClassifier classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: The model type to be used at the base layer of the ensemble model.\n",
    "        hp_range_map: A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        n_estimators: How many models to use in the ensemble\n",
    "        bootstrap: Wheter or not to use bootstrap sampling wehn training base estimators\n",
    "        stack_layer_estimator: Estimator type of the stack  layer model\n",
    "        base_stack_data_ratio: The ratio with which to split the data for straing the base and stack layers.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The estimator\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise ranomd state if set\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialise class variabels\n",
    "        self.base_estimator = base_estimator\n",
    "        self.hp_range_map = hp_range_map\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap = bootstrap\n",
    "        self.stack_layer_estimator = stack_layer_estimator\n",
    "        self.base_stack_data_ratio = base_stack_data_ratio\n",
    "        self.verbosity = verbosity\n",
    "        self.validate_parameters()\n",
    "        \n",
    "    \n",
    "    def validate_parameters(self):\n",
    "        if self.n_estimators < 1:\n",
    "             raise ValueError(\"n_estimators must be >= 1\")\n",
    "        if is_classifier(self.base_estimator) is False:\n",
    "            raise ValueError(\"base_estimator must be a classifier\")\n",
    "        if is_classifier(self.stack_layer_estimator) is False:\n",
    "            raise ValueError(\"stack_layer_estimator must be a classifier\")\n",
    "        if self.verbosity not in range(0,3):\n",
    "            raise ValueError(\"verbosity has range 0-2\")\n",
    "        if self.base_stack_data_ratio <= 0 or self.base_stack_data_ratio >= 1:\n",
    "            raise ValueError(\"base_stack_data_ratio must be greater than 0 and smaler than 1.\")\n",
    "        if self.hp_range_map is None:\n",
    "            self.hp_range_map = {}\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        def checkBootstrap(X, y):\n",
    "            if self.bootstrap is True:\n",
    "                return resample(X,y, replace=True)\n",
    "            return X,y \n",
    "        \n",
    "        def checkValue(value):\n",
    "            if type(value) is np.ndarray:\n",
    "                value = value.tolist()\n",
    "            elif type(value) is not list:\n",
    "                value = [value]\n",
    "            return value + [None]\n",
    "    \n",
    "        def generate_param_combinations():\n",
    "            params = []\n",
    "            for key, value in self.hp_range_map.items():\n",
    "                params.append(checkValue(value))\n",
    "                self.keys.append(key)\n",
    "            product = itertools.product(*params)\n",
    "            self.params = [ [ p for p in params ] for params in product ] \n",
    "        \n",
    "        def extract_params(n):\n",
    "            params = {}\n",
    "            for i,key in enumerate(self.keys):\n",
    "                if self.params[n][i] is not None:\n",
    "                    params[key] = self.params[n][i]\n",
    "            return params\n",
    "    \n",
    "        def fit_models(X_train, X_valid, y_train):\n",
    "            for i in range(0, self.n_estimators):\n",
    "                X_train, y_train = checkBootstrap(X_train, y_train)\n",
    "                params = extract_params(random.randint(0, (len(self.params)-1)))\n",
    "                clf = copy(self.base_estimator).set_params(**params)\n",
    "                clf.fit(X_train, y_train)\n",
    "                self.models.append(clf)\n",
    "                self.model_output.append(clf.predict(X_valid))\n",
    "        \n",
    "    \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=self.base_stack_data_ratio,\n",
    "                                                              random_state=self.random_state)\n",
    "\n",
    "        random.seed(self.random_state)\n",
    "        \n",
    "        self.params, self.keys, self.models, self.model_output = [], [], [], []\n",
    "        \n",
    "       #  Count the number of occurrences of each class in the target vector (uses mupy unique function that returns a list of unique values and their counts)\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        generate_param_combinations()\n",
    "        \n",
    "        fit_models(X_train, X_valid, y_train)\n",
    "        \n",
    "        self.stack_layer_estimator.fit(np.array(self.model_output).transpose(), y_valid)\n",
    "        \n",
    "        \n",
    "\n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "    \n",
    "        ensemble_predictions = np.array([model.predict(X) for model in self.models])\n",
    "                \n",
    "        return(self.stack_layer_estimator.predict(ensemble_predictions.transpose()))\n",
    "\n",
    "    \n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "    \n",
    "        ensemble_predictions = np.array([model.predict(X) for model in self.models])\n",
    "                \n",
    "        return(self.stack_layer_estimator.predict_proba(ensemble_predictions.transpose()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "n_estimators = 10\n",
    "base_estimator = svm.SVC()\n",
    "hyperparam_range = {\"kernel\":[\"rbf\", \"linear\"], \"C\":np.arange(0.1, 1.0, 0.1), \"gamma\":[0.1, 0.5], \"probability\":[True]}\n",
    "# hyperparam_range = None\n",
    "clf = StackedHeterogenousEnsembleClassifier(base_estimator, n_estimators, hyperparam_range, True, svm.SVC(probability=True), 0.7, verbosity = 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "clf.predict(iris.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the StackedHeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.91425156, 0.04981093, 0.03593751],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.13098717, 0.48205278, 0.38696006],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01021913, 0.44280363, 0.54697723],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01320159, 0.44165705, 0.54514136],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01021913, 0.44280363, 0.54697723],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01320159, 0.44165705, 0.54514136],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01021913, 0.44280363, 0.54697723],\n",
       "       [0.01320159, 0.44165705, 0.54514136],\n",
       "       [0.01021913, 0.44280363, 0.54697723],\n",
       "       [0.01320159, 0.44165705, 0.54514136],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01320159, 0.44165705, 0.54514136],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01320159, 0.44165705, 0.54514136],\n",
       "       [0.13098717, 0.48205278, 0.38696006],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.22286801, 0.52735032, 0.24978168],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01021913, 0.44280363, 0.54697723],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01021913, 0.44280363, 0.54697723],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395],\n",
       "       [0.01022447, 0.44280158, 0.54697395]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the StackedHeterogenousEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.98      0.92      0.95        50\n",
      "           2       0.92      0.98      0.95        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  46   4   50\n",
       "2           0   1  49   50\n",
       "All        50  47  53  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.95175771, 0.02863239, 0.0196099 ],\n",
       "       [0.95175771, 0.02863239, 0.0196099 ],\n",
       "       [0.95175771, 0.02863239, 0.0196099 ],\n",
       "       [0.95175771, 0.02863239, 0.0196099 ],\n",
       "       [0.95175771, 0.02863239, 0.0196099 ],\n",
       "       [0.95175771, 0.02863239, 0.0196099 ],\n",
       "       [0.95175771, 0.02863239, 0.0196099 ],\n",
       "       [0.95175771, 0.02863239, 0.0196099 ],\n",
       "       [0.95175771, 0.02863239, 0.0196099 ],\n",
       "       [0.95175771, 0.02863239, 0.0196099 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "n_estimators = 10\n",
    "base_estimator = svm.SVC()\n",
    "hyperparam_range = {\"kernel\":[\"rbf\", \"linear\"], \"C\":np.arange(0.1, 1.0, 0.1), \"gamma\":[0.1, 0.5], \"probability\":[True]}\n",
    "clf = StackedHeterogenousEnsembleClassifier(base_estimator, n_estimators, hyperparam_range, True, svm.SVC(probability=True), 0.7, verbosity = 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "y_pred = clf.predict_proba(iris.data)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.93333333 0.93333333 0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "0.96  +/-  0.044221663871405324\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare the Performance of the Different Ensembles Defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Experiment Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling_rate = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F40</th>\n",
       "      <th>F41</th>\n",
       "      <th>F42</th>\n",
       "      <th>F43</th>\n",
       "      <th>F44</th>\n",
       "      <th>F45</th>\n",
       "      <th>F46</th>\n",
       "      <th>F47</th>\n",
       "      <th>F48</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24676</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>0.030531</td>\n",
       "      <td>0.030548</td>\n",
       "      <td>0.030782</td>\n",
       "      <td>0.018643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.67644</td>\n",
       "      <td>0.2728</td>\n",
       "      <td>2.9799</td>\n",
       "      <td>-1.5004</td>\n",
       "      <td>-1.5004</td>\n",
       "      <td>-1.5001</td>\n",
       "      <td>-1.4993</td>\n",
       "      <td>-1.4994</td>\n",
       "      <td>-1.4995</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22916</th>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.021113</td>\n",
       "      <td>0.021128</td>\n",
       "      <td>0.021157</td>\n",
       "      <td>0.016504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.77003</td>\n",
       "      <td>31.7350</td>\n",
       "      <td>12.5680</td>\n",
       "      <td>-1.4990</td>\n",
       "      <td>-1.4990</td>\n",
       "      <td>-1.4989</td>\n",
       "      <td>-1.5003</td>\n",
       "      <td>-1.5003</td>\n",
       "      <td>-1.5002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41489</th>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.022599</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>0.022860</td>\n",
       "      <td>0.037797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63423</td>\n",
       "      <td>2.1662</td>\n",
       "      <td>5.1271</td>\n",
       "      <td>-1.5054</td>\n",
       "      <td>-1.5054</td>\n",
       "      <td>-1.5049</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4972</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16890</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.027722</td>\n",
       "      <td>0.027719</td>\n",
       "      <td>0.027755</td>\n",
       "      <td>0.047624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.46160</td>\n",
       "      <td>16.1280</td>\n",
       "      <td>8.9003</td>\n",
       "      <td>-1.5000</td>\n",
       "      <td>-1.5000</td>\n",
       "      <td>-1.5000</td>\n",
       "      <td>-1.4989</td>\n",
       "      <td>-1.4990</td>\n",
       "      <td>-1.4989</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13094</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.70112</td>\n",
       "      <td>2.3831</td>\n",
       "      <td>3.8496</td>\n",
       "      <td>-1.5047</td>\n",
       "      <td>-1.5049</td>\n",
       "      <td>-1.5043</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>-1.4981</td>\n",
       "      <td>-1.4980</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             F1        F2        F3        F4        F5        F6        F7  \\\n",
       "24676  0.000007 -0.000017 -0.000234 -0.000001 -0.000034 -0.000096  0.030531   \n",
       "22916 -0.000006 -0.000016 -0.000029  0.000003 -0.000002 -0.000034  0.021113   \n",
       "41489 -0.000008 -0.000013 -0.000248 -0.000016 -0.000025 -0.000035  0.022599   \n",
       "16890  0.000002  0.000003 -0.000037  0.000003  0.000002  0.000004  0.027722   \n",
       "13094 -0.000013 -0.000004 -0.000033  0.000002  0.000038  0.000021  0.005209   \n",
       "\n",
       "             F8        F9       F10  ...      F40      F41      F42     F43  \\\n",
       "24676  0.030548  0.030782  0.018643  ... -0.67644   0.2728   2.9799 -1.5004   \n",
       "22916  0.021128  0.021157  0.016504  ... -0.77003  31.7350  12.5680 -1.4990   \n",
       "41489  0.022612  0.022860  0.037797  ... -0.63423   2.1662   5.1271 -1.5054   \n",
       "16890  0.027719  0.027755  0.047624  ... -0.46160  16.1280   8.9003 -1.5000   \n",
       "13094  0.005214  0.005247  0.012618  ... -0.70112   2.3831   3.8496 -1.5047   \n",
       "\n",
       "          F44     F45     F46     F47     F48  label  \n",
       "24676 -1.5004 -1.5001 -1.4993 -1.4994 -1.4995      5  \n",
       "22916 -1.4990 -1.4989 -1.5003 -1.5003 -1.5002      5  \n",
       "41489 -1.5054 -1.5049 -1.4975 -1.4975 -1.4972      8  \n",
       "16890 -1.5000 -1.5000 -1.4989 -1.4990 -1.4989      4  \n",
       "13094 -1.5049 -1.5043 -1.4980 -1.4981 -1.4980      3  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Sensorless_drive_diagnosis.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing Values\")\n",
    "print(sum(dataset.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11    5319\n",
       "10    5319\n",
       "9     5319\n",
       "8     5319\n",
       "7     5319\n",
       "6     5319\n",
       "5     5319\n",
       "4     5319\n",
       "3     5319\n",
       "2     5319\n",
       "1     5319\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.pop('label')\n",
    "X = dataset\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test \\\n",
    "    = train_test_split(X, y, \\\n",
    "                       shuffle=True, \\\n",
    "                       stratify = y, \\\n",
    "                       train_size = 0.7)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid \\\n",
    "    = train_test_split(X_train_plus_valid, y_train_plus_valid, \\\n",
    "                        shuffle=True, \\\n",
    "                        stratify = y_train_plus_valid, \\\n",
    "                        train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the min max scalar object\n",
    "min_max_scaler = preprocessing.MinMaxScaler((-1,1))\n",
    "min_max_scaler.fit(X_train)\n",
    "\n",
    "# Train the scalar on the training dataset\n",
    "a = min_max_scaler.transform(X_train)\n",
    "\n",
    "# Little trick to stop transform from pandas daataframe to numpy array losing column namesWatch out for putting back in columns here\n",
    "cols = X_train.columns\n",
    "X_train = pd.DataFrame(a, columns = cols) \n",
    "\n",
    "# Also normalise other partitions\n",
    "a = min_max_scaler.transform(X_train_plus_valid)\n",
    "X_train_plus_valid = pd.DataFrame(a, columns = cols) \n",
    "a = min_max_scaler.transform(X_valid)\n",
    "X_valid = pd.DataFrame(a, columns = cols) \n",
    "a = min_max_scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(a, columns = cols) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = HeterogenousEnsembleClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Evaluation Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- First of all evaluate best classifier on the data with non stacked model\n",
    "\n",
    "-- Then use the same base classifier with varying different stacked estimators\n",
    "\n",
    "-- Then compare against "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your refelcection here (max 300 words)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

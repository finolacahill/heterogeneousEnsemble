{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Building Heterogenous Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Student 1 Name: Finola Cahill\n",
    "- Student 1 Number: 07645074"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted, check_random_state\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import load_iris\n",
    "import itertools\n",
    "from itertools import chain, combinations\n",
    "import random\n",
    "from copy import copy\n",
    "from scipy import stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: The Heterogenous Ensemble Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define HeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class HeterogenousEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer. Base models are different due to different hyper-parameters used.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator: scikit-learn estimator \n",
    "        The model type to be used at the base layer of the ensemble model.\n",
    "\n",
    "    hp_range_map: dictionary\n",
    "        A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        \n",
    "    n_estimators: int\n",
    "        How many models to use in the ensemble\n",
    "        \n",
    "    bootstrap: boolean\n",
    "        Wheter or not to use bootstrap sampling when training base estimators\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels.\n",
    "\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used, unless hyperparameter ranges are specified\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = HeterogenousEnsembleClassifier(tree.DecisionTreeClassifier(), {'max_depth':[5, 10, 15], })\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator = svm.SVC(), n_estimators = 10, hp_range_map = None, bootstrap = True, random_state=None, verbosity = 0):\n",
    "\n",
    "        \"\"\"Setup a SuperLearner classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: The model type to be used at the base layer of the ensemble model.\n",
    "        hp_range_map: A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        n_estimators: How many models to use in the ensemble\n",
    "        bootstrap: Wheter or not to use bootstrap sampling when training base estimators\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The estimator\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise ranomd state if set\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialise class variabels\n",
    "        self.base_estimator = base_estimator\n",
    "        self.hp_range_map = hp_range_map\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap = bootstrap\n",
    "        self.verbosity = verbosity\n",
    "        self.validate_parameters()\n",
    "    \n",
    "    def validate_parameters(self):\n",
    "        if self.n_estimators < 1:\n",
    "             raise ValueError(\"n_estimators must be >= 1\")\n",
    "        if is_classifier(self.base_estimator) is False:\n",
    "            raise ValueError(\"base_estimator must be a classifier\")\n",
    "        if self.verbosity not in range(0,3):\n",
    "            raise ValueError(\"verbosity has range 0-2\")\n",
    "        if self.hp_range_map is None:\n",
    "            self.hp_range_map = {}          \n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "                \n",
    "        def checkBootstrap(X, y):\n",
    "            if self.bootstrap is True:\n",
    "                return resample(X,y, replace=True)\n",
    "            return X,y \n",
    "                \n",
    "        def checkValue(value):\n",
    "            if type(value) is np.ndarray:\n",
    "                value = value.tolist()\n",
    "            elif type(value) is not list:\n",
    "                value = [value]\n",
    "            return value + [None]\n",
    "        \n",
    "        def generate_param_combinations():\n",
    "            params = []\n",
    "            for key, value in self.hp_range_map.items():\n",
    "                params.append(checkValue(value))\n",
    "                self.keys.append(key)\n",
    "            product = itertools.product(*params)\n",
    "            self.params = [ [ p for p in params ] for params in product ] \n",
    "        \n",
    "        def extract_params(n):\n",
    "            params = {}\n",
    "            for i,key in enumerate(self.keys):\n",
    "                if self.params[n][i] is not None:\n",
    "                    params[key] = self.params[n][i]\n",
    "            return params\n",
    "    \n",
    "        def fit_models(X, y):\n",
    "            for i in range(0, self.n_estimators):\n",
    "                X_train, y_train = checkBootstrap(X, y)\n",
    "                params = extract_params(random.randint(0, (len(self.params)-1)))\n",
    "                clf = copy(self.base_estimator).set_params(**params)\n",
    "                self.models.append(clf.fit(X_train, y_train))\n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        random.seed(self.random_state)\n",
    "        \n",
    "        self.params, self.keys, self.models = [], [], []\n",
    "        \n",
    "       #  Count the number of occurrences of each class in the target vector (uses mupy unique function that returns a list of unique values and their counts)\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        generate_param_combinations()\n",
    "        \n",
    "        fit_models(X,y)\n",
    "    \n",
    "\n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "    \n",
    "        ensemble_predictions = np.array([model.predict(X) for model in self.models])\n",
    "                \n",
    "        results = stats.mode(ensemble_predictions)[0]\n",
    "        \n",
    "        return results[0]\n",
    "    \n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        X = check_array(X)\n",
    "        \n",
    "        probability = []\n",
    "    \n",
    "        predictions = np.array([model.predict(X) for model in self.models]).transpose()\n",
    "        \n",
    "        for p in predictions:\n",
    "            key, val = np.unique(p, return_counts=True)\n",
    "            counts = dict(zip(key, val))\n",
    "            probability.append([(counts[c] / len(p)) if c in counts else 0.0 for c in self.classes_])\n",
    "        \n",
    "        return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the HeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "iris = load_iris()\n",
    "clf = HeterogenousEnsembleClassifier()\n",
    "clf.fit(iris.data, iris.target)\n",
    "# clf.predict(iris.data)\n",
    "# clf.predict_proba(iris.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the HeterogenousEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.92      0.98      0.95        50\n",
      "           2       0.98      0.92      0.95        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  49   1   50\n",
       "2           0   4  46   50\n",
       "All        50  53  47  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "base_estimator = svm.SVC()\n",
    "hyperparam_range = {\"kernel\":[\"rbf\", \"linear\"], \"C\":np.arange(0.1, 1.0, 10), \"gamma\":[0.1, 0.5], \"probability\":[True]}\n",
    "n_estimators = 10\n",
    "clf = HeterogenousEnsembleClassifier(base_estimator, n_estimators, hyperparam_range, verbosity = 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "y_pred = clf.predict_proba(iris.data)\n",
    "y_pred2 = clf.predict(iris.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         0.93333333 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "0.9733333333333334  +/-  0.03265986323710904\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: The StackedHeterogenousEnsembleClassifier Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define StackedHeterogenousEnsembleClassifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
    "class StackedHeterogenousEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer. Base models are different due to different hyper-parameters used. Aggrefgattion is perfomred using a stack layer model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_estimator: scikit-learn estimator \n",
    "        The model type to be used at the base layer of the ensemble model.\n",
    "\n",
    "    hp_range_map: dictionary\n",
    "        A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        \n",
    "    n_estimators: int\n",
    "        How many models to use in the ensemble\n",
    "        \n",
    "    bootstrap: boolean\n",
    "        Whether or not to use bootstrap sampling wehn training base estimators\n",
    "    \n",
    "    stack_layer_estimator: scikit-learn estimator \n",
    "        Estimator type of the stack  layer model\n",
    "        \n",
    "    base_stack_data_ratio: float\n",
    "        The ratio with which to split the data for straing the base and stack layers.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : array of shape = [n_classes] \n",
    "        The classes labels.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The default values for most base learners are used, unless hyperparameter ranges are specified\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.datasets import load_iris\n",
    "    >>> from sklearn.model_selection import cross_val_score\n",
    "    >>> clf = StackedHeterogenousEnsembleClassifier(tree.DecisionTreeClassifier(), {'max_depth':[5, 10, 15], })\n",
    "    >>> iris = load_iris()\n",
    "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "\n",
    "    \"\"\"\n",
    "    # Constructor for the classifier object\n",
    "    def __init__(self, base_estimator = svm.SVC(), n_estimators = 10, hp_range_map = None, bootstrap = True, stack_layer_estimator = svm.SVC(), base_stack_data_ratio = 0.7, random_state=None, verbosity = 0):\n",
    "\n",
    "        \"\"\"Setup a StackedHeterogenousEnsembleClassifier classifier .\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_estimator: The model type to be used at the base layer of the ensemble model.\n",
    "        hp_range_map: A dictinary of hyperparamters and the ranges of values that will be used from them\n",
    "        n_estimators: How many models to use in the ensemble\n",
    "        bootstrap: Wheter or not to use bootstrap sampling wehn training base estimators\n",
    "        stack_layer_estimator: Estimator type of the stack  layer model\n",
    "        base_stack_data_ratio: The ratio with which to split the data for straing the base and stack layers.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        The estimator\n",
    "        \"\"\"     \n",
    "\n",
    "        # Initialise ranomd state if set\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Initialise class variabels\n",
    "        self.base_estimator = base_estimator\n",
    "        self.hp_range_map = hp_range_map\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap = bootstrap\n",
    "        self.stack_layer_estimator = stack_layer_estimator\n",
    "        self.base_stack_data_ratio = base_stack_data_ratio\n",
    "        self.verbosity = verbosity\n",
    "        self.validate_parameters()\n",
    "        \n",
    "    \n",
    "    def validate_parameters(self):\n",
    "        if self.n_estimators < 1:\n",
    "             raise ValueError(\"n_estimators must be >= 1\")\n",
    "        if is_classifier(self.base_estimator) is False:\n",
    "            raise ValueError(\"base_estimator must be a classifier\")\n",
    "        if is_classifier(self.stack_layer_estimator) is False:\n",
    "            raise ValueError(\"stack_layer_estimator must be a classifier\")\n",
    "        if self.verbosity not in range(0,3):\n",
    "            raise ValueError(\"verbosity has range 0-2\")\n",
    "        if self.base_stack_data_ratio <= 0 or self.base_stack_data_ratio >= 1:\n",
    "            raise ValueError(\"base_stack_data_ratio must be greater than 0 and smaler than 1.\")\n",
    "        if self.hp_range_map is None:\n",
    "            self.hp_range_map = {}\n",
    "\n",
    "    # The fit function to train a classifier\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        def checkBootstrap(X, y):\n",
    "            if self.bootstrap is True:\n",
    "                return resample(X,y, replace=True)\n",
    "            return X,y \n",
    "        \n",
    "        def checkValue(value):\n",
    "            if type(value) is np.ndarray:\n",
    "                value = value.tolist()\n",
    "            elif type(value) is not list:\n",
    "                value = [value]\n",
    "            return value + [None]\n",
    "    \n",
    "        def generate_param_combinations():\n",
    "            params = []\n",
    "            for key, value in self.hp_range_map.items():\n",
    "                params.append(checkValue(value))\n",
    "                self.keys.append(key)\n",
    "            product = itertools.product(*params)\n",
    "            self.params = [ [ p for p in params ] for params in product ] \n",
    "        \n",
    "        def extract_params(n):\n",
    "            params = {}\n",
    "            for i,key in enumerate(self.keys):\n",
    "                if self.params[n][i] is not None:\n",
    "                    params[key] = self.params[n][i]\n",
    "            return params\n",
    "    \n",
    "        def fit_models(X_train, X_valid, y_train):\n",
    "            for i in range(0, self.n_estimators):\n",
    "                X_train, y_train = checkBootstrap(X_train, y_train)\n",
    "                params = extract_params(random.randint(0, (len(self.params)-1)))\n",
    "                clf = copy(self.base_estimator).set_params(**params)\n",
    "                clf.fit(X_train, y_train)\n",
    "                self.models.append(clf)\n",
    "                self.model_output.append(clf.predict(X_valid))\n",
    "        \n",
    "    \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=self.base_stack_data_ratio,\n",
    "                                                              random_state=self.random_state)\n",
    "\n",
    "        random.seed(self.random_state)\n",
    "        \n",
    "        self.params, self.keys, self.models, self.model_output = [], [], [], []\n",
    "        \n",
    "       #  Count the number of occurrences of each class in the target vector (uses mupy unique function that returns a list of unique values and their counts)\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        generate_param_combinations()\n",
    "        \n",
    "        fit_models(X_train, X_valid, y_train)\n",
    "        \n",
    "        self.stack_layer_estimator.fit(np.array(self.model_output).transpose(), y_valid)\n",
    "        \n",
    "        \n",
    "\n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict(self, X):\n",
    "        \n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "    \n",
    "        ensemble_predictions = np.array([model.predict(X) for model in self.models])\n",
    "                \n",
    "        return(self.stack_layer_estimator.predict(ensemble_predictions.transpose()))\n",
    "\n",
    "    \n",
    "#     # The predict function to make a set of predictions for a set of query instances\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        check_is_fitted(self, ['models'])\n",
    "        \n",
    "        # Check that the input features match the type and shape of the training features\n",
    "        X = check_array(X)\n",
    "    \n",
    "        ensemble_predictions = np.array([model.predict(X) for model in self.models])\n",
    "                \n",
    "        return(self.stack_layer_estimator.predict_proba(ensemble_predictions.transpose()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "n_estimators = 10\n",
    "base_estimator = svm.SVC()\n",
    "hyperparam_range = {\"kernel\":[\"rbf\", \"linear\"], \"C\":np.arange(0.1, 1.0, 0.1), \"gamma\":[0.1, 0.5], \"probability\":[True]}\n",
    "# hyperparam_range = None\n",
    "clf = StackedHeterogenousEnsembleClassifier(base_estimator, n_estimators, hyperparam_range, True, svm.SVC(probability=True), 0.7, verbosity = 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "clf.predict(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the StackedHeterogenousEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a simple test using the StackedHeterogenousEnsembleClassifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.91      0.86      0.89        50\n",
      "           2       0.87      0.92      0.89        50\n",
      "\n",
      "    accuracy                           0.93       150\n",
      "   macro avg       0.93      0.93      0.93       150\n",
      "weighted avg       0.93      0.93      0.93       150\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2  All\n",
       "True                      \n",
       "0          50   0   0   50\n",
       "1           0  43   7   50\n",
       "2           0   4  46   50\n",
       "All        50  47  53  150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.94228742, 0.0282854 , 0.02942718],\n",
       "       [0.94228742, 0.0282854 , 0.02942718],\n",
       "       [0.94228742, 0.0282854 , 0.02942718],\n",
       "       [0.94228742, 0.0282854 , 0.02942718],\n",
       "       [0.94228742, 0.0282854 , 0.02942718],\n",
       "       [0.94228742, 0.0282854 , 0.02942718],\n",
       "       [0.94228742, 0.0282854 , 0.02942718],\n",
       "       [0.94228742, 0.0282854 , 0.02942718],\n",
       "       [0.94228742, 0.0282854 , 0.02942718],\n",
       "       [0.94228742, 0.0282854 , 0.02942718]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "n_estimators = 10\n",
    "base_estimator = svm.SVC()\n",
    "hyperparam_range = {\"kernel\":[\"rbf\", \"linear\"], \"C\":np.arange(0.1, 1.0, 0.1), \"gamma\":[0.1, 0.5], \"probability\":[True]}\n",
    "clf = StackedHeterogenousEnsembleClassifier(base_estimator, n_estimators, hyperparam_range, True, svm.SVC(probability=True), 0.7, verbosity = 1)\n",
    "clf.fit(iris.data, iris.target)\n",
    "y_pred = clf.predict(iris.data)\n",
    "print(metrics.classification_report(iris.target, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "display(pd.crosstab(np.array(iris.target), y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "y_pred = clf.predict_proba(iris.data)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a cross validation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93333333 0.93333333 1.         0.93333333 0.86666667 1.\n",
      " 0.86666667 0.86666667 1.         0.86666667]\n",
      "0.9266666666666667  +/-  0.05537749241945382\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores), \" +/- \", np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare the Performance of the Different Ensembles Defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Experiment Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take only a sample of the dataset for fast testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Sensorless_drive_diagnosis.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Evaluation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your refelcection here (max 300 words)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
